# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uWBet_kE61V6n_jfg2Fvk-dk1iKwcXA_
"""

!pip install torch torchvision matplotlib pillow

import torch
import torchvision
from torchvision import transforms
from torchvision.datasets import CocoDetection
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torch.utils.data import DataLoader

val_dataset = CocoDetection(root='./data', annFile='./data/annotations/instances_val2017.json', image_set='val2017', transform=transforms.ToTensor())

!pip install pycocotools

import torchvision.datasets as datasets

import os
import requests
import zipfile
from tqdm import tqdm

def download_and_extract_coco():
    data_dir = './data'
    annotation_dir = os.path.join(data_dir, 'annotations')
    image_dir = os.path.join(data_dir, 'images')

    os.makedirs(data_dir, exist_ok=True)
    os.makedirs(annotation_dir, exist_ok=True)
    os.makedirs(image_dir, exist_ok=True)

    annotation_zip_file = os.path.join(annotation_dir, 'annotations_trainval2017.zip')
    if not os.path.exists(annotation_zip_file):
        print("Downloading annotations...")
        with open(annotation_zip_file, 'wb') as f:
            response = requests.get('http://images.cocodataset.org/annotations/annotations_trainval2017.zip', stream=True)
            total_length = int(response.headers.get('content-length'))
            for chunk in tqdm(response.iter_content(chunk_size=1024), total=(total_length / 1024) + 1):
                if chunk:
                    f.write(chunk)
                    f.flush()
        print("Annotations downloaded.")

    annotation_extracted_folder = os.path.join(annotation_dir, 'annotations')
    if not os.path.exists(annotation_extracted_folder):
        print("Extracting annotations...")
        with zipfile.ZipFile(annotation_zip_file, 'r') as zip_ref:
            zip_ref.extractall(annotation_extracted_folder)
        print("Annotations extracted.")

    image_zip_file = os.path.join(data_dir, 'val2017.zip')
    if not os.path.exists(image_zip_file):
        print("Downloading images (validation set)...")
        with open(image_zip_file, 'wb') as f:
            response = requests.get('http://images.cocodataset.org/zips/val2017.zip', stream=True)
            total_length = int(response.headers.get('content-length'))
            for chunk in tqdm(response.iter_content(chunk_size=1024), total=(total_length / 1024) + 1):
                if chunk:
                    f.write(chunk)
                    f.flush()
        print("Images (validation set) downloaded.")

    image_extracted_folder = os.path.join(data_dir, 'images', 'val2017')
    if not os.path.exists(image_extracted_folder):
        print("Extracting images (validation set)...")
        with zipfile.ZipFile(image_zip_file, 'r') as zip_ref:
            zip_ref.extractall(os.path.join(data_dir, 'images'))
        print("Images (validation set) extracted.")

download_and_extract_coco()

import torch
import torchvision
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np

model = fasterrcnn_resnet50_fpn(pretrained=True)

model.eval()

x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]
predictions = model(x)

predictions

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

val_dataset = CocoDetection(root='./data', annFile='/content/data/annotations/annotations/annotations/instances_val2017.json',transform=transforms.ToTensor())

from PIL import Image
def get_predictions(model, image_path):
    image = Image.open(image_path)
    image_tensor = transform(image).to(device)

    with torch.no_grad():
        prediction = model([image_tensor])

    return prediction

transform = transforms.Compose([
    transforms.ToTensor()
])

image_path = '/content/data/images/val2017/000000000139.jpg'
prediction = get_predictions(model, image_path)
print(prediction)

img = Image.open(image_path)
img = np.array(img)
img

def plot_prediction(image_path, prediction):
    img = Image.open(image_path)
    img = np.array(img)

    fig, ax = plt.subplots(1)
    ax.imshow(img)

    boxes = prediction[0]['boxes'].cpu().numpy()
    labels = prediction[0]['labels'].cpu().numpy()
    scores = prediction[0]['scores'].cpu().numpy()

    for box, label, score in zip(boxes, labels, scores):
        box = [int(coord) for coord in box]
        rect = patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1], linewidth=1, edgecolor='r', facecolor='none')
        ax.add_patch(rect)
        label_name = val_dataset.coco.cats[label]['name']
        ax.text(box[0], box[1], f'{label_name} {score:.2f}', bbox=dict(facecolor='white', alpha=0.5))

    plt.axis('off')
    plt.show()

plot_prediction(image_path, prediction)

image_path = '/content/data/images/val2017/000000000285.jpg'
prediction = get_predictions(model, image_path)
plot_prediction(image_path, prediction)

image_path = '/content/data/images/val2017/000000000632.jpg'
prediction = get_predictions(model, image_path)
plot_prediction(image_path, prediction)

def evaluate(model, dataset):
    predictions = []
    targets = []

    for img_id in range(len(dataset)):
        image, target = dataset[img_id]
        image = image.unsqueeze(0).to(device)
        with torch.no_grad():
            prediction = model(image)
        predictions.append(prediction)
        targets.append(target)

    return predictions, targets

annotation_file = '/content/data/annotations/annotations/annotations/instances_val2017.json'
val_dataset = CocoDetection(root='/content/data/images/val2017/', annFile=annotation_file, transform=transform)

predictions, targets = evaluate(model, val_dataset)

import matplotlib.pyplot as plt
from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval
annotation_file = '/content/data/annotations/annotations/annotations/instances_val2017.json'
coco_gt = COCO(annotation_file)

coco_dt = []

val_dataset = CocoDetection(root='/content/data/images/val2017/', annFile=annotation_file, transform=transform)

for img_id, prediction in enumerate(predictions):
    image_id = val_dataset.coco.imgs[val_dataset.ids[img_id]]['id']
    boxes = prediction[0]['boxes'].cpu().numpy()
    scores = prediction[0]['scores'].cpu().numpy()
    labels = prediction[0]['labels'].cpu().numpy()

    for box, score, label in zip(boxes, scores, labels):
        coco_dt.append({
            'image_id': image_id,
            'category_id': val_dataset.coco.cats[label]['id'],
            'bbox': [float(box[0]), float(box[1]), float(box[2] - box[0]), float(box[3] - box[1])],
            'score': float(score)
        })

coco_dt_anns = coco_gt.loadRes(coco_dt)

coco_eval = COCOeval(coco_gt, coco_dt_anns, 'bbox')
coco_eval.evaluate()
coco_eval.accumulate()
coco_eval.summarize()

print(f"Average Precision (AP): {coco_eval.stats[0]}")
print(f"Average Recall (AR): {coco_eval.stats[1]}")
print(f"Average Precision 50 (AP50): {coco_eval.stats[2]}")
print(f"Average Precision 75 (AP75): {coco_eval.stats[3]}")
print(f"Average Precision small (APs): {coco_eval.stats[4]}")
print(f"Average Precision medium (APm): {coco_eval.stats[5]}")
print(f"Average Precision large (APl): {coco_eval.stats[6]}")

